{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaygwu/robotics/blob/main/SyntheticCells_Neuromorphic_StateMachine_Moderate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "id": "d179fd58",
      "cell_type": "markdown",
      "source": [
        "# Synthetic Cells as Neuromorphic State Machines  \n",
        "\n",
        "**Topic:** Synthetic Cells (Colloidal State Machines), Memristors, Hybrid Control, Edge AI\n",
        "\n",
        "## Learning goals\n",
        "By the end of this notebook, you will be able to:\n",
        "1. Simulate a **memristor** as a simple nonlinear dynamical system (stateful resistor)\n",
        "2. Implement the **SynCell AND logic** (Light ∧ Chemical → memory write)\n",
        "3. Compare **hardware thresholding** vs a tiny **AI classifier**\n",
        "4. Compute a simple **energy budget** for switching / inference\n",
        "5. *(Optional)* Simulate a **swarm** of SynCells mapping an environment\n",
        "\n",
        "> This notebook is self-contained: it generates synthetic data and figures automatically.\n"
      ],
      "metadata": {
        "id": "d179fd58"
      }
    },
    {
      "id": "df6fcff3",
      "cell_type": "code",
      "metadata": {
        "id": "df6fcff3"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# Imports (keep it lightweight)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(7)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "print(\"✅ Imports loaded. Random seed set to 7.\")\n"
      ],
      "outputs": []
    },
    {
      "id": "8960e54b",
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1) Memristor model (stateful resistor)\n",
        "\n",
        "We’ll use a **moderate** toy model that captures the key idea:\n",
        "- A memristor has an internal state variable **w(t)** (bounded in [0,1])\n",
        "- Resistance depends on that state:\n",
        "\\[ R(w) = R_{ON} \\cdot w + R_{OFF} \\cdot (1-w) \\]\n",
        "- The state evolves based on applied voltage (or current). We use a *thresholded* drift model:\n",
        "\\[ \\dot{w} = \\alpha \\cdot \\max(0, |V|-V_{th}) \\cdot \\text{sign}(V) - \\beta (w- w_0) \\]\n",
        "Intuition:\n",
        "- If |V| is below threshold, state barely moves\n",
        "- If |V| exceeds threshold, state shifts (writing)\n",
        "- A small “leak” term pulls w back toward a baseline **w0**\n",
        "\n",
        "This is not the only model, but it’s enough to reason about **state, transitions, and energy**.\n"
      ],
      "metadata": {
        "id": "8960e54b"
      }
    },
    {
      "id": "a3e1ad82",
      "cell_type": "code",
      "metadata": {
        "id": "a3e1ad82"
      },
      "execution_count": null,
      "source": [
        "\n",
        "def memristor_step(w, V, dt, params):\n",
        "    \"\"\"One Euler step for a thresholded memristor state model.\"\"\"\n",
        "    alpha = params['alpha']\n",
        "    beta  = params['beta']\n",
        "    Vth   = params['Vth']\n",
        "    w0    = params['w0']\n",
        "\n",
        "    drive = max(0.0, abs(V) - Vth)\n",
        "    dw = alpha * drive * np.sign(V) - beta*(w - w0)\n",
        "    w_new = w + dt*dw\n",
        "    w_new = min(1.0, max(0.0, w_new))  # clamp to [0,1]\n",
        "    return w_new\n",
        "\n",
        "def R_of_w(w, Ron, Roff):\n",
        "    return Ron*w + Roff*(1-w)\n",
        "\n",
        "m_params = dict(alpha=3.0, beta=0.15, Vth=0.18, w0=0.15)\n",
        "Ron, Roff = 2e4, 2e6   # 20 kΩ ON, 2 MΩ OFF\n",
        "dt = 1e-3              # 1 ms step\n",
        "\n",
        "print(\"✅ Memristor model defined.\")\n",
        "print(\"Params:\", m_params, \"Ron=\", Ron, \"Roff=\", Roff, \"dt=\", dt)\n"
      ],
      "outputs": []
    },
    {
      "id": "a1575b1e",
      "cell_type": "markdown",
      "source": [
        "### 1.1 Simulate a voltage sweep (hysteresis-style)\n",
        "\n",
        "We’ll apply a triangular waveform and compute I = V / R(w).  \n",
        "You should see **history-dependent behavior** (a crude hysteresis).\n"
      ],
      "metadata": {
        "id": "a1575b1e"
      }
    },
    {
      "id": "a7664d57",
      "cell_type": "code",
      "metadata": {
        "id": "a7664d57"
      },
      "execution_count": null,
      "source": [
        "\n",
        "def triangular_wave(num_steps, Vmax):\n",
        "    q = num_steps // 4\n",
        "    seg1 = np.linspace(0, Vmax, q, endpoint=False)\n",
        "    seg2 = np.linspace(Vmax, 0, q, endpoint=False)\n",
        "    seg3 = np.linspace(0, -Vmax, q, endpoint=False)\n",
        "    seg4 = np.linspace(-Vmax, 0, num_steps - 3*q)\n",
        "    return np.concatenate([seg1, seg2, seg3, seg4])\n",
        "\n",
        "num_steps = 2000\n",
        "Vmax = 0.5\n",
        "Vs = triangular_wave(num_steps, Vmax)\n",
        "\n",
        "w = 0.15\n",
        "ws, Rs, Is = [], [], []\n",
        "for V in Vs:\n",
        "    w = memristor_step(w, V, dt, m_params)\n",
        "    R = R_of_w(w, Ron, Roff)\n",
        "    I = V / R\n",
        "    ws.append(w); Rs.append(R); Is.append(I)\n",
        "\n",
        "ws = np.array(ws); Rs = np.array(Rs); Is = np.array(Is)\n",
        "\n",
        "print(\"Diagnostics:\")\n",
        "print(\"  w min/max:\", ws.min(), ws.max())\n",
        "print(\"  R min/max (Ohm):\", Rs.min(), Rs.max())\n",
        "print(\"  I min/max (A):\", Is.min(), Is.max())\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(Vs, Is, linewidth=1)\n",
        "plt.xlabel(\"Voltage V (V)\")\n",
        "plt.ylabel(\"Current I (A)\")\n",
        "plt.title(\"Memristor I–V trajectory (toy hysteresis)\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ws, linewidth=1)\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"State w\")\n",
        "plt.title(\"Internal state w(t)\")\n",
        "plt.show()\n"
      ],
      "outputs": []
    },
    {
      "id": "82a825ff",
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2) SynCell AND logic: Light ∧ Chemical → write memory\n",
        "\n",
        "We’ll model:\n",
        "- Light intensity L ∈ [0,1]\n",
        "- Chemical concentration C ∈ [0,1]\n",
        "- Photodiode voltage: \\[ V_{ph} = k_L \\cdot L \\]\n",
        "- Chemiresistor resistance: \\[ R_{ch}(C) = \\frac{1}{G_0 + \\gamma C} \\]\n",
        "- Voltage divider (toy):  \n",
        "\\[ V_{mem} = V_{ph} \\cdot \\frac{R_{mem}}{R_{mem}+R_{ch}} \\]\n",
        "\n",
        "We “write” if |Vmem| exceeds Vth long enough.\n"
      ],
      "metadata": {
        "id": "82a825ff"
      }
    },
    {
      "id": "f754c096",
      "cell_type": "code",
      "metadata": {
        "id": "f754c096"
      },
      "execution_count": null,
      "source": [
        "\n",
        "kL = 0.45         # photodiode gain\n",
        "G0 = 2e-8         # baseline conductance (S)\n",
        "gamma = 9e-8      # analyte sensitivity (S per unit chemical)\n",
        "\n",
        "def R_ch_of_C(C):\n",
        "    return 1.0 / (G0 + gamma*C)\n",
        "\n",
        "def simulate_synCell_write(L, C, steps=200, dt=1e-3):\n",
        "    Vph = kL * L\n",
        "    w = 0.15\n",
        "    for _ in range(steps):\n",
        "        Rmem = R_of_w(w, Ron, Roff)\n",
        "        Rch = R_ch_of_C(C)\n",
        "        Vmem = Vph * (Rmem/(Rmem + Rch))\n",
        "        w = memristor_step(w, Vmem, dt, m_params)\n",
        "    return (w > 0.6), w\n",
        "\n",
        "for L, C in [(0.2,0.2), (0.9,0.2), (0.2,0.9), (0.9,0.9)]:\n",
        "    on, w_final = simulate_synCell_write(L, C)\n",
        "    print(f\"L={L:.1f}, C={C:.1f} -> ON={on}, final w={w_final:.3f}\")\n"
      ],
      "outputs": []
    },
    {
      "id": "d5805e05",
      "cell_type": "markdown",
      "source": [
        "### 2.1 Decision boundary plot\n",
        "\n",
        "Sweep (L,C) and plot where the SynCell writes memory.\n"
      ],
      "metadata": {
        "id": "d5805e05"
      }
    },
    {
      "id": "5ae858cd",
      "cell_type": "code",
      "metadata": {
        "id": "5ae858cd"
      },
      "execution_count": null,
      "source": [
        "\n",
        "grid = 60\n",
        "Ls = np.linspace(0,1,grid)\n",
        "Cs = np.linspace(0,1,grid)\n",
        "\n",
        "ON = np.zeros((grid, grid), dtype=int)\n",
        "Wf = np.zeros((grid, grid), dtype=float)\n",
        "\n",
        "for i, L in enumerate(Ls):\n",
        "    for j, C in enumerate(Cs):\n",
        "        on, w_final = simulate_synCell_write(L, C)\n",
        "        ON[j,i] = 1 if on else 0\n",
        "        Wf[j,i] = w_final\n",
        "\n",
        "print(\"ON fraction:\", ON.mean())\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(ON, origin=\"lower\", extent=[0,1,0,1], aspect=\"auto\")\n",
        "plt.xlabel(\"Light L\")\n",
        "plt.ylabel(\"Chemical C\")\n",
        "plt.title(\"SynCell write region (1=ON, 0=OFF)\")\n",
        "plt.colorbar(label=\"ON\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(Wf, origin=\"lower\", extent=[0,1,0,1], aspect=\"auto\")\n",
        "plt.xlabel(\"Light L\")\n",
        "plt.ylabel(\"Chemical C\")\n",
        "plt.title(\"Final memristor state w after exposure\")\n",
        "plt.colorbar(label=\"w\")\n",
        "plt.show()\n"
      ],
      "outputs": []
    },
    {
      "id": "0ed17677",
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3) “AI layer”: a tiny classifier vs hardware thresholding\n",
        "\n",
        "We generate labeled data from the physical SynCell model and train **logistic regression** (from scratch):\n",
        "\\[ \\hat{y} = \\sigma(\\theta_0 + \\theta_1 L + \\theta_2 C) \\]\n",
        "\n",
        "Interpretation:\n",
        "- Hardware: physics performs inference\n",
        "- AI: learns the boundary from data\n"
      ],
      "metadata": {
        "id": "0ed17677"
      }
    },
    {
      "id": "3710367e",
      "cell_type": "code",
      "metadata": {
        "id": "3710367e"
      },
      "execution_count": null,
      "source": [
        "\n",
        "N = 2000\n",
        "L_data = np.random.rand(N)\n",
        "C_data = np.random.rand(N)\n",
        "\n",
        "y = np.zeros(N, dtype=int)\n",
        "w_final = np.zeros(N)\n",
        "\n",
        "for n in range(N):\n",
        "    on, wf = simulate_synCell_write(L_data[n], C_data[n])\n",
        "    y[n] = 1 if on else 0\n",
        "    w_final[n] = wf\n",
        "\n",
        "X = np.stack([np.ones(N), L_data, C_data], axis=1)\n",
        "\n",
        "print(\"Dataset created.\")\n",
        "print(\"  Positive class rate:\", y.mean())\n",
        "print(\"  X shape:\", X.shape)\n"
      ],
      "outputs": []
    },
    {
      "id": "7aacc09a",
      "cell_type": "code",
      "metadata": {
        "id": "7aacc09a"
      },
      "execution_count": null,
      "source": [
        "\n",
        "theta = np.zeros(3)\n",
        "lr = 1.0\n",
        "epochs = 1200\n",
        "\n",
        "def loss_and_grad(theta, X, y):\n",
        "    z = X @ theta\n",
        "    p = sigmoid(z)\n",
        "    eps = 1e-12\n",
        "    loss = -(y*np.log(p+eps) + (1-y)*np.log(1-p+eps)).mean()\n",
        "    grad = (X.T @ (p - y)) / len(y)\n",
        "    return loss, grad\n",
        "\n",
        "loss_hist = []\n",
        "for ep in range(epochs):\n",
        "    loss, grad = loss_and_grad(theta, X, y)\n",
        "    theta -= lr*grad\n",
        "    loss_hist.append(loss)\n",
        "    if ep in [0,1,2,5,10,50,100,300,600,1199]:\n",
        "        print(f\"epoch {ep:4d} | loss={loss:.4f} | theta={theta}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_hist)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Log-loss\")\n",
        "plt.title(\"Training curve (logistic regression)\")\n",
        "plt.show()\n",
        "\n",
        "p = sigmoid(X @ theta)\n",
        "yhat = (p >= 0.5).astype(int)\n",
        "acc = (yhat == y).mean()\n",
        "print(\"Final accuracy:\", acc)\n"
      ],
      "outputs": []
    },
    {
      "id": "a5e38cb3",
      "cell_type": "markdown",
      "source": [
        "### 3.1 Visualize learned decision boundary\n",
        "\n",
        "Overlay the AI boundary on the physical ON/OFF map.\n"
      ],
      "metadata": {
        "id": "a5e38cb3"
      }
    },
    {
      "id": "be8d3803",
      "cell_type": "code",
      "metadata": {
        "id": "be8d3803"
      },
      "execution_count": null,
      "source": [
        "\n",
        "P_grid = np.zeros((grid, grid))\n",
        "for i, L in enumerate(Ls):\n",
        "    for j, C in enumerate(Cs):\n",
        "        x = np.array([1.0, L, C])\n",
        "        P_grid[j,i] = sigmoid(x @ theta)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(P_grid, origin=\"lower\", extent=[0,1,0,1], aspect=\"auto\")\n",
        "plt.xlabel(\"Light L\")\n",
        "plt.ylabel(\"Chemical C\")\n",
        "plt.title(\"AI model: predicted P(ON)\")\n",
        "plt.colorbar(label=\"P(ON)\")\n",
        "plt.show()\n",
        "\n",
        "Ls_line = np.linspace(0,1,200)\n",
        "Cs_line = -(theta[0] + theta[1]*Ls_line)/theta[2] if abs(theta[2]) > 1e-9 else np.nan*Ls_line\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(ON, origin=\"lower\", extent=[0,1,0,1], aspect=\"auto\")\n",
        "plt.plot(Ls_line, Cs_line, linewidth=2)\n",
        "plt.ylim(0,1); plt.xlim(0,1)\n",
        "plt.xlabel(\"Light L\")\n",
        "plt.ylabel(\"Chemical C\")\n",
        "plt.title(\"Physical ON/OFF map with AI boundary overlay\")\n",
        "plt.colorbar(label=\"ON\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Theta:\", theta)\n"
      ],
      "outputs": []
    },
    {
      "id": "8d7b2fa1",
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4) Energy-aware computation: switching cost vs “inference” cost\n",
        "\n",
        "We estimate hardware energy:\n",
        "\\[ E \\approx \\sum_t |V_{mem}(t) \\cdot I_{mem}(t)| \\, dt \\]\n",
        "with \\(I_{mem}=V_{mem}/R_{mem}(w)\\).\n",
        "\n",
        "Then compare to a toy digital inference energy (order-of-magnitude placeholder).\n"
      ],
      "metadata": {
        "id": "8d7b2fa1"
      }
    },
    {
      "id": "1ecaf090",
      "cell_type": "code",
      "metadata": {
        "id": "1ecaf090"
      },
      "execution_count": null,
      "source": [
        "\n",
        "def synCell_energy(L, C, steps=200, dt=1e-3):\n",
        "    Vph = kL * L\n",
        "    w = 0.15\n",
        "    E = 0.0\n",
        "    for _ in range(steps):\n",
        "        Rmem = R_of_w(w, Ron, Roff)\n",
        "        Rch = R_ch_of_C(C)\n",
        "        Vmem = Vph * (Rmem/(Rmem + Rch))\n",
        "        Imem = Vmem / Rmem\n",
        "        E += abs(Vmem * Imem) * dt\n",
        "        w = memristor_step(w, Vmem, dt, m_params)\n",
        "    return E, w\n",
        "\n",
        "samples = [(0.9,0.9),(0.9,0.2),(0.2,0.9),(0.2,0.2)]\n",
        "for L,C in samples:\n",
        "    E, w = synCell_energy(L,C)\n",
        "    print(f\"L={L:.1f}, C={C:.1f} -> E≈{E:.3e} J, final w={w:.3f}\")\n"
      ],
      "outputs": []
    },
    {
      "id": "e4b06a78",
      "cell_type": "code",
      "metadata": {
        "id": "e4b06a78"
      },
      "execution_count": null,
      "source": [
        "\n",
        "E_map = np.zeros((grid, grid))\n",
        "for i, L in enumerate(Ls):\n",
        "    for j, C in enumerate(Cs):\n",
        "        E, wf = synCell_energy(L, C)\n",
        "        E_map[j,i] = E\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(E_map, origin=\"lower\", extent=[0,1,0,1], aspect=\"auto\")\n",
        "plt.xlabel(\"Light L\")\n",
        "plt.ylabel(\"Chemical C\")\n",
        "plt.title(\"Estimated hardware energy E(L,C)\")\n",
        "plt.colorbar(label=\"Energy (J)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Mean energy when OFF:\", E_map[ON==0].mean())\n",
        "print(\"Mean energy when ON :\", E_map[ON==1].mean())\n"
      ],
      "outputs": []
    },
    {
      "id": "a8849d0b",
      "cell_type": "code",
      "metadata": {
        "id": "a8849d0b"
      },
      "execution_count": null,
      "source": [
        "\n",
        "E_MAC = 1e-12  # toy: 1 pJ per multiply-add (placeholder)\n",
        "E_digital = 5 * E_MAC\n",
        "\n",
        "print(\"Toy digital inference energy per sample:\", E_digital, \"J\")\n",
        "\n",
        "for L,C in samples:\n",
        "    E_hw, w = synCell_energy(L,C)\n",
        "    ratio = E_hw / E_digital\n",
        "    print(f\"L={L:.1f}, C={C:.1f}: E_hw={E_hw:.2e} J, E_digital={E_digital:.2e} J, ratio={ratio:.1e}x\")\n"
      ],
      "outputs": []
    },
    {
      "id": "184d8a50",
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5) Optional: Swarm simulation (distributed mapping)\n",
        "\n",
        "We simulate a 2D chemical plume, drop N SynCells randomly, and let each cell decide ON/OFF locally.\n",
        "Then we visualize ON/OFF points over the field.\n"
      ],
      "metadata": {
        "id": "184d8a50"
      }
    },
    {
      "id": "4046dac0",
      "cell_type": "code",
      "metadata": {
        "id": "4046dac0"
      },
      "execution_count": null,
      "source": [
        "\n",
        "def chemical_field(x, y):\n",
        "    c1 = np.exp(-((x-0.35)**2 + (y-0.6)**2)/(2*0.06**2))\n",
        "    c2 = 0.7*np.exp(-((x-0.7)**2 + (y-0.3)**2)/(2*0.08**2))\n",
        "    return np.clip(c1 + c2, 0, 1)\n",
        "\n",
        "def light_field(x, y):\n",
        "    return np.clip(0.6 + 0.4*x, 0, 1)\n",
        "\n",
        "Nswarm = 800\n",
        "xs = np.random.rand(Nswarm)\n",
        "ys = np.random.rand(Nswarm)\n",
        "\n",
        "Cs_local = np.array([chemical_field(x,y) for x,y in zip(xs,ys)])\n",
        "Ls_local = np.array([light_field(x,y) for x,y in zip(xs,ys)])\n",
        "\n",
        "on_flags = np.zeros(Nswarm, dtype=int)\n",
        "for i in range(Nswarm):\n",
        "    on, wf = simulate_synCell_write(Ls_local[i], Cs_local[i])\n",
        "    on_flags[i] = 1 if on else 0\n",
        "\n",
        "print(\"Swarm ON rate:\", on_flags.mean())\n",
        "\n",
        "res = 200\n",
        "xx = np.linspace(0,1,res)\n",
        "yy = np.linspace(0,1,res)\n",
        "C_bg = np.zeros((res,res))\n",
        "for i, y in enumerate(yy):\n",
        "    for j, x in enumerate(xx):\n",
        "        C_bg[i,j] = chemical_field(x,y)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(C_bg, origin=\"lower\", extent=[0,1,0,1], aspect=\"auto\")\n",
        "plt.scatter(xs[on_flags==0], ys[on_flags==0], s=10)\n",
        "plt.scatter(xs[on_flags==1], ys[on_flags==1], s=12)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Swarm mapping: chemical field + SynCell ON/OFF points\")\n",
        "plt.show()\n"
      ],
      "outputs": []
    },
    {
      "id": "b1467d95",
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6) Short questions (submit answers)\n",
        "\n",
        "1. Which parameter(s) most strongly controls the AND boundary: **kL**, **gamma**, or **Vth**? Why?  \n",
        "2. In your energy plots, where is energy “wasted” (high energy but OFF)? Interpret physically.  \n",
        "3. Logistic regression learned a linear boundary. The physical boundary can be nonlinear. What caused nonlinearity?  \n",
        "4. If you were designing a *next-gen SynCell*, what would you change to improve: energy efficiency, memory reliability, AI capability?  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b1467d95"
      }
    }
  ]
}